{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: New definition \n",
      "    +(AbstractArray{T,N},DataArray{T,N}) at /Users/quetzal/.julia/v0.3/DataArrays/src/operators.jl:326\n",
      "is ambiguous with: \n",
      "    +(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:17.\n",
      "To fix, define \n",
      "    +(AbstractImageDirect{T,N},DataArray{T,N})\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    +(AbstractArray{T,N},AbstractDataArray{T,N}) at /Users/quetzal/.julia/v0.3/DataArrays/src/operators.jl:349\n",
      "is ambiguous with: \n",
      "    +(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:17.\n",
      "To fix, define \n",
      "    +(AbstractImageDirect{T,N},AbstractDataArray{T,N})\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    -(AbstractArray{T,N},DataArray{T,N}) at /Users/quetzal/.julia/v0.3/DataArrays/src/operators.jl:326\n",
      "is ambiguous with: \n",
      "    -(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:31.\n",
      "To fix, define \n",
      "    -(AbstractImageDirect{T,N},DataArray{T,N})\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    -(AbstractArray{T,N},AbstractDataArray{T,N}) at /Users/quetzal/.julia/v0.3/DataArrays/src/operators.jl:349\n",
      "is ambiguous with: \n",
      "    -(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:31.\n",
      "To fix, define \n",
      "    -(AbstractImageDirect{T,N},AbstractDataArray{T,N})\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .*(Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}),AbstractArray{T,N}...) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:282\n",
      "is ambiguous with: \n",
      "    .*(AbstractArray{T,N},AbstractImageDirect{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:46.\n",
      "To fix, define \n",
      "    .*(Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}),AbstractImageDirect{T,N})\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .*(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}),AbstractArray{T,N}...) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:282\n",
      "is ambiguous with: \n",
      "    .*(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:45.\n",
      "To fix, define \n",
      "    .*(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .+(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}),AbstractArray{T,N}...) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:284\n",
      "is ambiguous with: \n",
      "    .+(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:19.\n",
      "To fix, define \n",
      "    .+(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .-(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .-(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:34.\n",
      "To fix, define \n",
      "    .-(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    ./(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    ./(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:49.\n",
      "To fix, define \n",
      "    ./(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .==(AbstractArray{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:317\n",
      "is ambiguous with: \n",
      "    .==(AbstractImageDirect{Bool,N},AbstractArray{Bool,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:125.\n",
      "To fix, define \n",
      "    .==(AbstractImageDirect{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .==(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .==(AbstractImageDirect{Bool,N},AbstractArray{Bool,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:125.\n",
      "To fix, define \n",
      "    .==(AbstractImageDirect{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .==(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .==(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:126.\n",
      "To fix, define \n",
      "    .==(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .>(AbstractArray{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:317\n",
      "is ambiguous with: \n",
      "    .>(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:123.\n",
      "To fix, define \n",
      "    .>(AbstractImageDirect{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .>(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .>(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:123.\n",
      "To fix, define \n",
      "    .>(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .<(AbstractArray{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:317\n",
      "is ambiguous with: \n",
      "    .<(AbstractImageDirect{Bool,N},AbstractArray{Bool,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:121.\n",
      "To fix, define \n",
      "    .<(AbstractImageDirect{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .<(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .<(AbstractImageDirect{Bool,N},AbstractArray{Bool,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:121.\n",
      "To fix, define \n",
      "    .<(AbstractImageDirect{Bool,N},Union(DataArray{Bool,N},PooledDataArray{Bool,R<:Integer,N}))\n",
      "before the new definition.\n",
      "Warning: New definition \n",
      "    .<(AbstractArray{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N})) at /Users/quetzal/.julia/v0.3/DataArrays/src/broadcast.jl:272\n",
      "is ambiguous with: \n",
      "    .<(AbstractImageDirect{T,N},AbstractArray{T,N}) at /Users/quetzal/.julia/v0.3/Images/src/algorithms.jl:122.\n",
      "To fix, define \n",
      "    .<(AbstractImageDirect{T,N},Union(PooledDataArray{T,R<:Integer,N},DataArray{T,N}))\n",
      "before the new definition.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n",
      " * CUDA       disabled by default\n",
      " * Native Ext enabled (MOCHA_USE_NATIVE_EXT environment variable detected)\n",
      "Mocha configured, continue loading module...\n",
      "Loading native extension libmochaext.so...\n",
      "Native extension loaded\n"
     ]
    }
   ],
   "source": [
    "using Images\n",
    "using DataFrames\n",
    "using HDF5\n",
    "using MLBase\n",
    "\n",
    "use_gpu = false\n",
    "if use_gpu\n",
    "    ENV[\"MOCHA_USE_CUDA\"] = \"true\"\n",
    "else\n",
    "    ENV[\"MOCHA_USE_NATIVE_EXT\"] = \"true\"\n",
    "    blas_set_num_threads(2)\n",
    "end\n",
    "\n",
    "using Mocha\n",
    "srand(333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of data set: (6283,2)\n",
      "Size of test data set: (6220,2)\n"
     ]
    }
   ],
   "source": [
    "imageSize = (20,20,1) # 20 x 20 pixel x 1 color\n",
    "\n",
    "#Set location of data files, folders\n",
    "path = \"data\"\n",
    "\n",
    "#Read information about training data , IDs.\n",
    "labelsInfo = readtable(\"$(path)/trainLabels.csv\")\n",
    "\n",
    "println(\"Size of data set: \", size(labelsInfo))\n",
    "\n",
    "labelsInfoTest = readtable(\"$(path)/sampleSubmission.csv\")\n",
    "\n",
    "println(\"Size of test data set: \", size(labelsInfoTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><tr><th></th><th>ID</th><th>Class</th><th>Labels</th></tr><tr><th>1</th><td>1</td><td>n</td><td>0</td></tr><tr><th>2</th><td>2</td><td>8</td><td>1</td></tr><tr><th>3</th><td>3</td><td>T</td><td>2</td></tr><tr><th>4</th><td>4</td><td>I</td><td>3</td></tr><tr><th>5</th><td>5</td><td>R</td><td>4</td></tr><tr><th>6</th><td>6</td><td>W</td><td>5</td></tr></table>"
      ],
      "text/plain": [
       "6x3 DataFrame\n",
       "| Row | ID | Class | Labels |\n",
       "|-----|----|-------|--------|\n",
       "| 1   | 1  | \"n\"   | 0      |\n",
       "| 2   | 2  | \"8\"   | 1      |\n",
       "| 3   | 3  | \"T\"   | 2      |\n",
       "| 4   | 4  | \"I\"   | 3      |\n",
       "| 5   | 5  | \"R\"   | 4      |\n",
       "| 6   | 6  | \"W\"   | 5      |"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need labels from 0 to N-1 for Mocha\n",
    "labs = unique(labelsInfo[:Class])\n",
    "dic = Dict(zip(collect(labs), 0:length(labs)-1))\n",
    "create_labs(classes) = map(k -> dic[k], classes)\n",
    "labelsInfo[:Labels] = create_labs(labelsInfo[:Class])\n",
    "labelsInfoTest[:Labels] = create_labs(labelsInfoTest[:Class])\n",
    "head(labelsInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split on train and validation sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train data set: (4713,3)\n",
      "Size of the validation data set: (785,3)\n",
      "Size of the holdout data set: (785,3)\n"
     ]
    }
   ],
   "source": [
    "srand(12345)\n",
    "n = length(labelsInfo[:ID])\n",
    "trainSet = shuffle(1:n .> n*0.25)\n",
    "labelsInfoTrain = labelsInfo[trainSet,:]\n",
    "\n",
    "# Hold out some data from validation set\n",
    "srand(12345)\n",
    "n = length(labelsInfo[!trainSet,:ID])\n",
    "validationSet = shuffle(1:n .> n*0.5)\n",
    "labelsInfoValid = labelsInfo[!trainSet,:][validationSet,:]\n",
    "labelsInfoHoldout = labelsInfo[!trainSet,:][!validationSet,:]\n",
    "\n",
    "println(\"Size of the train data set: \", size(labelsInfoTrain))\n",
    "println(\"Size of the validation data set: \", size(labelsInfoValid))\n",
    "println(\"Size of the holdout data set: \", size(labelsInfoHoldout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Images from the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readImages (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function readImages(typeData, labelsInfo, imageSize, path)\n",
    "    w, h, c = imageSize\n",
    "    n = length(labelsInfo[:ID])\n",
    "    x = float32(zeros(w,h,c,n))\n",
    "    for (index, idImage) in enumerate(labelsInfo[:ID]) \n",
    "        #Read image file \n",
    "        nameFile = \"$(path)/$(typeData)Resized/$(idImage).Bmp\"\n",
    "        img = imread(nameFile)\n",
    "\n",
    "        #Convert img to float values \n",
    "        img = convert(Array{Gray}, img)\n",
    "        img = convert(Array{Float32}, img)\n",
    "        img = (img - mean(img)) / std(img)\n",
    "        x[:,:,:,index] = reshape(img, w, h, c)\n",
    "        \n",
    "    end \n",
    "    \n",
    "    return x\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: OSX reader: indexed color images not implemented\n",
      "WARNING: OSX reader: indexed color images not implemented\n",
      "WARNING: OSX reader: indexed color images not implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the train images set: (20,20,1,4713)\n",
      "Size of the validation images set: (20,20,1,785)\n",
      "Size of the holdout images set: (20,20,1,785)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: OSX reader: indexed color images not implemented\n",
      "WARNING: OSX reader: indexed color images not implemented\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the test images set: (20,20,1,6220)\n"
     ]
    }
   ],
   "source": [
    "trainImages = readImages(\"train\", labelsInfoTrain, imageSize, path)\n",
    "println(\"Size of the train images set: \", size(trainImages))\n",
    "\n",
    "validImages = readImages(\"train\", labelsInfoValid, imageSize, path)\n",
    "println(\"Size of the validation images set: \", size(validImages))\n",
    "\n",
    "holdoutImages = readImages(\"train\", labelsInfoHoldout, imageSize, path)\n",
    "println(\"Size of the holdout images set: \", size(validImages))\n",
    "\n",
    "testImages = readImages(\"test\", labelsInfoTest, imageSize, path)\n",
    "println(\"Size of the test images set: \", size(testImages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images into HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import data to HDF5 format\n",
    "function convert_to_HDF5(typeData, imageSet, labelsInfo, path)\n",
    "    w, h, c, n = size(imageSet)\n",
    "    \n",
    "    HDF5.h5open(\"$(path)/$(typeData).hdf5\", \"w\") do h5\n",
    "        dset_data = d_create(h5, \"data\", datatype(Float32), dataspace(w, h, c, n))\n",
    "        dset_data[:,:,:,:] =  imageSet\n",
    "        \n",
    "        dset_label = d_create(h5, \"label\", datatype(Float32), dataspace(1,n))\n",
    "        dset_label[1,:] = labelsInfo[:Labels]\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "convert_to_HDF5(\"train\", trainImages, labelsInfoTrain, path)\n",
    "convert_to_HDF5(\"validation\", validImages, labelsInfoValid, path)\n",
    "convert_to_HDF5(\"holdout\", holdoutImages, labelsInfoValid, path)\n",
    "convert_to_HDF5(\"test\", testImages, labelsInfoTest, path)\n",
    "\n",
    "run(`echo $(path)/train.hdf5` |> \"$(path)/train.txt\")\n",
    "run(`echo $(path)/validation.hdf5` |> \"$(path)/validation.txt\")\n",
    "run(`echo $(path)/holdout.hdf5` |> \"$(path)/holdout.txt\")\n",
    "run(`echo $(path)/test.hdf5` |> \"$(path)/test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network main params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solver will run for 4700 iterations\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH = 100\n",
    "EPOCH = int(round(size(trainImages)[4] / TRAIN_BATCH))\n",
    "MAXITER = 100*EPOCH\n",
    "\n",
    "nclasses = length(unique(labelsInfoTrain[:Class]))\n",
    "nunits = (\"nunits\", [2400])\n",
    "base_mom = (\"base_mom\", [0.1])\n",
    "base_lr = (\"base_lr\", [0.5])\n",
    "\n",
    "println(\"Solver will run for \", MAXITER, \" iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict (generic function with 1 method)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function predict(predict_net::Net, base_dir::String) \n",
    "    load_snapshot(predict_net, base_dir)\n",
    "    \n",
    "    init(predict_net)\n",
    "    forward_epoch(predict_net)\n",
    "\n",
    "    batch = []\n",
    "    if isa(predict_net.states[end].layer, AccuracyLayer)\n",
    "        batch = to_array(predict_net.states[end-1].blobs[1])\n",
    "    else \n",
    "        batch = to_array(predict_net.states[end].blobs[1])\n",
    "    end\n",
    "    \n",
    "    n = size(batch)[2]\n",
    "    pred = zeros(n)\n",
    "    for i in 1:n\n",
    "        pred[i] = indmax(batch[:,i]) - 1\n",
    "    end\n",
    "    \n",
    "    return(pred)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Neural Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "configure_training (generic function with 1 method)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function configure_training(nunits)\n",
    "    data_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"$(path)/train.txt\", \n",
    "                                    batch_size=TRAIN_BATCH)\n",
    "    fc1_layer   = InnerProductLayer(name=\"fc1\", output_dim=nunits, neuron=Neurons.ReLU(),\n",
    "                                    weight_init = GaussianInitializer(std=0.01),\n",
    "                                    bottoms=[:data], tops=[:fc1])\n",
    "    fc2_layer   = InnerProductLayer(name=\"fc2\", output_dim=nunits, neuron=Neurons.ReLU(),\n",
    "                                    weight_init = GaussianInitializer(std=0.01),\n",
    "                                    weight_cons = L2Cons(4.5),\n",
    "                                    bottoms=[:fc1], tops=[:fc2])\n",
    "    fc3_layer   = InnerProductLayer(name=\"out\", output_dim=nclasses, bottoms=[:fc2],\n",
    "                                    weight_init = ConstantInitializer(0),\n",
    "                                    weight_cons = L2Cons(4.5),\n",
    "                                    tops=[:out])\n",
    "    loss_layer  = SoftmaxLossLayer(name=\"loss\", bottoms=[:out,:label])\n",
    "    \n",
    "    backend = use_gpu ? GPUBackend() : CPUBackend()\n",
    "    init(backend)\n",
    "\n",
    "    # setup dropout for the different layers\n",
    "    # we use 20% dropout on the inputs and 50% dropout in the hidden layers\n",
    "    # as these values were previously found to be good defaults\n",
    "    drop_input  = DropoutLayer(name=\"drop_in\", bottoms=[:data], ratio=0.1)\n",
    "    drop_fc1 = DropoutLayer(name=\"drop_fc1\", bottoms=[:fc1], ratio=0.5)\n",
    "    drop_fc2  = DropoutLayer(name=\"drop_fc2\", bottoms=[:fc2], ratio=0.5)\n",
    "\n",
    "    common_layers = [fc1_layer, fc2_layer, fc3_layer]\n",
    "    #drop_layers = [drop_input, drop_fc1, drop_fc2]\n",
    "    # put training net together, note that the correct ordering will automatically be established by the constructor\n",
    "    net = Net(\"SVHN-train\", backend, [data_layer, common_layers..., loss_layer])\n",
    "    \n",
    "    # Configure accuracy check on validation set during training process\n",
    "    valid_batch = size(validImages)[4]\n",
    "    valid_data_layer = AsyncHDF5DataLayer(\n",
    "        name=\"validation-data\", \n",
    "        source=\"$(path)/validation.txt\", \n",
    "        batch_size=valid_batch)\n",
    "    acc_layer = AccuracyLayer(name=\"validation-accuracy\", bottoms=[:out, :label], report_error=true)\n",
    "    valid_net = Net(\"SVHN-validation\", backend, [valid_data_layer, common_layers..., acc_layer])\n",
    "    \n",
    "    return(net, valid_net) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "configure_solver (generic function with 2 methods)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function configure_solver(niter, base_mom, base_lr, epoch, base_dir, regu_coef=0.00)\n",
    "    params = SolverParameters(\n",
    "                max_iter=niter,\n",
    "                regu_coef=0.00,\n",
    "                mom_policy=MomPolicy.Linear(base_mom, 0.0008, epoch, 0.99),\n",
    "                lr_policy=LRPolicy.Step(base_lr, 0.998, epoch), \n",
    "                load_from=base_dir)\n",
    "\n",
    "    solver = SGD(params)\n",
    "    \n",
    "    return(solver)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup coffee breaks for statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "configure_coffebreaks (generic function with 1 method)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function configure_coffebreaks(solver, valid_net, base_dir)\n",
    "    setup_coffee_lounge(solver, save_into=\"$(base_dir)/statistics.jld\", every_n_iter=5000)\n",
    "\n",
    "    # report training progress every 100 iterations\n",
    "    add_coffee_break(solver, TrainingSummary(show_lr=true, show_mom=true), every_n_iter=100)\n",
    "\n",
    "    # Report validation perfomance every 500 iterations\n",
    "    add_coffee_break(solver, ValidationPerformance(valid_net), every_n_iter=500)\n",
    "    \n",
    "    # save snapshots every 1000 iterations\n",
    "    add_coffee_break(solver, Snapshot(base_dir), every_n_iter=500) \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure grid serach params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalfun (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evalfun(netInfo)\n",
    "    pred = predict(netInfo[:valid_net], netInfo[:base_dir])\n",
    "    model_perfomance = mean(pred .== netInfo[:validLabels])\n",
    "    \n",
    "    return(model_perfomance)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estfun (generic function with 1 method)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function estfun(nunits, base_mom, base_lr)\n",
    "    snapshot_dir = \"snapshot_mlp_$(nunits)_$(nunits)_$(base_mom)_$(base_lr)\"\n",
    "    net, valid_net = configure_training(nunits)\n",
    "    #println(net)\n",
    "    #println(valid_net)\n",
    "    solver = configure_solver(MAXITER, base_mom, base_lr, EPOCH, snapshot_dir)\n",
    "    configure_coffebreaks(solver, valid_net, snapshot_dir)\n",
    "    solve(solver, net) \n",
    "    model = {:net => net, \n",
    "             :valid_net => valid_net,\n",
    "             :base_dir => snapshot_dir, \n",
    "             :validLabels => labelsInfoValid[:Labels]}\n",
    "    \n",
    "    return(model)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19-Aug 16:31:27:INFO:root:Constructing net SVHN-train on CPUBackend...\n",
      "19-Aug 16:31:27:INFO:root:Topological sorting 5 layers...\n",
      "19-Aug 16:31:27:INFO:root:Setup layers...\n",
      "19-Aug 16:31:27:INFO:root:Network constructed!\n",
      "19-Aug 16:31:27:INFO:root:Constructing net SVHN-validation on CPUBackend...\n",
      "19-Aug 16:31:27:INFO:root:Topological sorting 5 layers...\n",
      "19-Aug 16:31:27:INFO:root:Setup layers...\n",
      "19-Aug 16:31:27:DEBUG:root:InnerProductLayer(fc1): sharing weights and bias\n",
      "19-Aug 16:31:27:DEBUG:root:InnerProductLayer(fc2): sharing weights and bias\n",
      "19-Aug 16:31:27:DEBUG:root:InnerProductLayer(out): sharing weights and bias\n",
      "19-Aug 16:31:27:INFO:root:Network constructed!\n",
      "19-Aug 16:31:27:DEBUG:root:Checking network topology for back-propagation\n",
      "19-Aug 16:31:27:DEBUG:root:Init network SVHN-train\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter weight for layer fc1\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter bias for layer fc1\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter weight for layer fc2\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter bias for layer fc2\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter weight for layer out\n",
      "19-Aug 16:31:27:DEBUG:root:Init parameter bias for layer out\n",
      "19-Aug 16:31:27:DEBUG:root:Initializing coffee breaks\n",
      "19-Aug 16:31:27:DEBUG:root:Init network SVHN-validation\n",
      "19-Aug 16:31:27:INFO:root:Snapshot directory mlp_1200_1200_0.1_0.5 already exists\n",
      "19-Aug 16:31:27:INFO:root:ITER = 000000:: TRAIN obj-val = 4.12713432:: LR = 0.50000000:: MOM = 0.10000000\n",
      "19-Aug 16:31:28:INFO:root:\n",
      "19-Aug 16:31:28:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "19-Aug 16:31:28:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:31:28:INFO:root:  Accuracy (avg over 785) = 1.2739%\n",
      "19-Aug 16:31:28:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:31:28:INFO:root:\n",
      "19-Aug 16:31:28:INFO:root:Saving snapshot to snapshot-000000.jld...\n",
      "19-Aug 16:31:28:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:31:28:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:31:28:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:31:28:DEBUG:root:Entering solver loop\n",
      "19-Aug 16:32:09:INFO:root:ITER = 000100:: TRAIN obj-val = 2.22847366:: LR = 0.49800200:: MOM = 0.10160000\n",
      "19-Aug 16:32:48:INFO:root:ITER = 000200:: TRAIN obj-val = 1.44125760:: LR = 0.49601198:: MOM = 0.10320000\n",
      "19-Aug 16:33:32:INFO:root:ITER = 000300:: TRAIN obj-val = 0.82645589:: LR = 0.49402992:: MOM = 0.10480000\n",
      "19-Aug 16:34:20:INFO:root:ITER = 000400:: TRAIN obj-val = 0.63810825:: LR = 0.49205578:: MOM = 0.10640000\n",
      "19-Aug 16:35:05:INFO:root:ITER = 000500:: TRAIN obj-val = 0.26423052:: LR = 0.49008952:: MOM = 0.10800000\n",
      "19-Aug 16:35:07:INFO:root:\n",
      "19-Aug 16:35:07:INFO:root:## Performance on Validation Set after 500 iterations\n",
      "19-Aug 16:35:07:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:35:07:INFO:root:  Accuracy (avg over 785) = 63.5669%\n",
      "19-Aug 16:35:07:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:35:07:INFO:root:\n",
      "19-Aug 16:35:07:INFO:root:Saving snapshot to snapshot-000500.jld...\n",
      "19-Aug 16:35:07:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:35:07:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:35:07:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:35:54:INFO:root:ITER = 000600:: TRAIN obj-val = 0.17656338:: LR = 0.48813112:: MOM = 0.10960000\n",
      "19-Aug 16:36:40:INFO:root:ITER = 000700:: TRAIN obj-val = 0.02474504:: LR = 0.48618055:: MOM = 0.11120000\n",
      "19-Aug 16:37:27:INFO:root:ITER = 000800:: TRAIN obj-val = 0.01924023:: LR = 0.48326930:: MOM = 0.11360000\n",
      "19-Aug 16:38:06:INFO:root:ITER = 000900:: TRAIN obj-val = 0.02406394:: LR = 0.48133815:: MOM = 0.11520000\n",
      "19-Aug 16:38:47:INFO:root:ITER = 001000:: TRAIN obj-val = 0.01844312:: LR = 0.47941473:: MOM = 0.11680000\n",
      "19-Aug 16:38:48:INFO:root:\n",
      "19-Aug 16:38:48:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "19-Aug 16:38:48:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:38:48:INFO:root:  Accuracy (avg over 785) = 64.3312%\n",
      "19-Aug 16:38:48:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:38:48:INFO:root:\n",
      "19-Aug 16:38:48:INFO:root:Saving snapshot to snapshot-001000.jld...\n",
      "19-Aug 16:38:48:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:38:48:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:38:48:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:39:28:INFO:root:ITER = 001100:: TRAIN obj-val = 0.01889543:: LR = 0.47749899:: MOM = 0.11840000\n",
      "19-Aug 16:40:09:INFO:root:ITER = 001200:: TRAIN obj-val = 0.00613048:: LR = 0.47559090:: MOM = 0.12000000\n",
      "19-Aug 16:40:54:INFO:root:ITER = 001300:: TRAIN obj-val = 0.00291198:: LR = 0.47369044:: MOM = 0.12160000\n",
      "19-Aug 16:41:36:INFO:root:ITER = 001400:: TRAIN obj-val = 0.00258018:: LR = 0.47179757:: MOM = 0.12320000\n",
      "19-Aug 16:42:22:INFO:root:ITER = 001500:: TRAIN obj-val = 0.00189402:: LR = 0.46991227:: MOM = 0.12480000\n",
      "19-Aug 16:42:24:INFO:root:\n",
      "19-Aug 16:42:24:INFO:root:## Performance on Validation Set after 1500 iterations\n",
      "19-Aug 16:42:24:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:42:24:INFO:root:  Accuracy (avg over 785) = 65.2229%\n",
      "19-Aug 16:42:24:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:42:24:INFO:root:\n",
      "19-Aug 16:42:24:INFO:root:Saving snapshot to snapshot-001500.jld...\n",
      "19-Aug 16:42:24:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:42:24:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:42:24:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:43:10:INFO:root:ITER = 001600:: TRAIN obj-val = 0.00214556:: LR = 0.46709843:: MOM = 0.12720000\n",
      "19-Aug 16:43:51:INFO:root:ITER = 001700:: TRAIN obj-val = 0.00151807:: LR = 0.46523191:: MOM = 0.12880000\n",
      "19-Aug 16:44:35:INFO:root:ITER = 001800:: TRAIN obj-val = 0.00142932:: LR = 0.46337284:: MOM = 0.13040000\n",
      "19-Aug 16:45:12:INFO:root:ITER = 001900:: TRAIN obj-val = 0.00154163:: LR = 0.46152120:: MOM = 0.13200000\n",
      "19-Aug 16:45:53:INFO:root:ITER = 002000:: TRAIN obj-val = 0.00111371:: LR = 0.45967696:: MOM = 0.13360000\n",
      "19-Aug 16:45:54:INFO:root:\n",
      "19-Aug 16:45:54:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "19-Aug 16:45:54:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:45:54:INFO:root:  Accuracy (avg over 785) = 65.4777%\n",
      "19-Aug 16:45:54:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:45:54:INFO:root:\n",
      "19-Aug 16:45:54:INFO:root:Saving snapshot to snapshot-002000.jld...\n",
      "19-Aug 16:45:54:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:45:54:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:45:54:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:46:39:INFO:root:ITER = 002100:: TRAIN obj-val = 0.00123810:: LR = 0.45784009:: MOM = 0.13520000\n",
      "19-Aug 16:47:28:INFO:root:ITER = 002200:: TRAIN obj-val = 0.00105362:: LR = 0.45601056:: MOM = 0.13680000\n",
      "19-Aug 16:48:14:INFO:root:ITER = 002300:: TRAIN obj-val = 0.00093912:: LR = 0.45418835:: MOM = 0.13840000\n",
      "19-Aug 16:48:58:INFO:root:ITER = 002400:: TRAIN obj-val = 0.00106269:: LR = 0.45146866:: MOM = 0.14080000\n",
      "19-Aug 16:49:38:INFO:root:ITER = 002500:: TRAIN obj-val = 0.00072696:: LR = 0.44966459:: MOM = 0.14240000\n",
      "19-Aug 16:49:39:INFO:root:\n",
      "19-Aug 16:49:39:INFO:root:## Performance on Validation Set after 2500 iterations\n",
      "19-Aug 16:49:39:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:49:39:INFO:root:  Accuracy (avg over 785) = 65.4777%\n",
      "19-Aug 16:49:39:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:49:39:INFO:root:\n",
      "19-Aug 16:49:39:INFO:root:Saving snapshot to snapshot-002500.jld...\n",
      "19-Aug 16:49:39:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:49:39:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:49:39:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:50:20:INFO:root:ITER = 002600:: TRAIN obj-val = 0.00085167:: LR = 0.44786773:: MOM = 0.14400000\n",
      "19-Aug 16:51:05:INFO:root:ITER = 002700:: TRAIN obj-val = 0.00069126:: LR = 0.44607805:: MOM = 0.14560000\n",
      "19-Aug 16:51:50:INFO:root:ITER = 002800:: TRAIN obj-val = 0.00086328:: LR = 0.44429553:: MOM = 0.14720000\n",
      "19-Aug 16:52:33:INFO:root:ITER = 002900:: TRAIN obj-val = 0.00102698:: LR = 0.44252012:: MOM = 0.14880000\n",
      "19-Aug 16:53:13:INFO:root:ITER = 003000:: TRAIN obj-val = 0.00068011:: LR = 0.44075181:: MOM = 0.15040000\n",
      "19-Aug 16:53:14:INFO:root:\n",
      "19-Aug 16:53:14:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "19-Aug 16:53:14:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:53:14:INFO:root:  Accuracy (avg over 785) = 65.4777%\n",
      "19-Aug 16:53:14:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:53:14:INFO:root:\n",
      "19-Aug 16:53:14:INFO:root:Saving snapshot to snapshot-003000.jld...\n",
      "19-Aug 16:53:14:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:53:14:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:53:14:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:53:52:INFO:root:ITER = 003100:: TRAIN obj-val = 0.00072157:: LR = 0.43899057:: MOM = 0.15200000\n",
      "19-Aug 16:54:33:INFO:root:ITER = 003200:: TRAIN obj-val = 0.00057255:: LR = 0.43636189:: MOM = 0.15440000\n",
      "19-Aug 16:55:16:INFO:root:ITER = 003300:: TRAIN obj-val = 0.00049201:: LR = 0.43461819:: MOM = 0.15600000\n",
      "19-Aug 16:55:56:INFO:root:ITER = 003400:: TRAIN obj-val = 0.00057403:: LR = 0.43288145:: MOM = 0.15760000\n",
      "19-Aug 16:56:39:INFO:root:ITER = 003500:: TRAIN obj-val = 0.00057502:: LR = 0.43115166:: MOM = 0.15920000\n",
      "19-Aug 16:56:40:INFO:root:\n",
      "19-Aug 16:56:40:INFO:root:## Performance on Validation Set after 3500 iterations\n",
      "19-Aug 16:56:40:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:56:40:INFO:root:  Accuracy (avg over 785) = 65.4777%\n",
      "19-Aug 16:56:40:INFO:root:---------------------------------------------------------\n",
      "19-Aug 16:56:40:INFO:root:\n",
      "19-Aug 16:56:40:INFO:root:Saving snapshot to snapshot-003500.jld...\n",
      "19-Aug 16:56:40:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 16:56:40:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 16:56:40:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 16:57:19:INFO:root:ITER = 003600:: TRAIN obj-val = 0.00083620:: LR = 0.42942878:: MOM = 0.16080000\n",
      "19-Aug 16:57:58:INFO:root:ITER = 003700:: TRAIN obj-val = 0.00043424:: LR = 0.42771278:: MOM = 0.16240000\n",
      "19-Aug 16:58:39:INFO:root:ITER = 003800:: TRAIN obj-val = 0.00047845:: LR = 0.42600364:: MOM = 0.16400000\n",
      "19-Aug 16:59:22:INFO:root:ITER = 003900:: TRAIN obj-val = 0.00056198:: LR = 0.42430133:: MOM = 0.16560000\n",
      "19-Aug 17:00:03:INFO:root:ITER = 004000:: TRAIN obj-val = 0.00038771:: LR = 0.42176061:: MOM = 0.16800000\n",
      "19-Aug 17:00:04:INFO:root:\n",
      "19-Aug 17:00:04:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "19-Aug 17:00:04:INFO:root:---------------------------------------------------------\n",
      "19-Aug 17:00:04:INFO:root:  Accuracy (avg over 785) = 65.3503%\n",
      "19-Aug 17:00:04:INFO:root:---------------------------------------------------------\n",
      "19-Aug 17:00:04:INFO:root:\n",
      "19-Aug 17:00:04:INFO:root:Saving snapshot to snapshot-004000.jld...\n",
      "19-Aug 17:00:04:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 17:00:04:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 17:00:04:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 17:00:45:INFO:root:ITER = 004100:: TRAIN obj-val = 0.00054827:: LR = 0.42007525:: MOM = 0.16960000\n",
      "19-Aug 17:01:26:INFO:root:ITER = 004200:: TRAIN obj-val = 0.00034024:: LR = 0.41839663:: MOM = 0.17120000\n",
      "19-Aug 17:02:08:INFO:root:ITER = 004300:: TRAIN obj-val = 0.00054070:: LR = 0.41672472:: MOM = 0.17280000\n",
      "19-Aug 17:02:50:INFO:root:ITER = 004400:: TRAIN obj-val = 0.00043556:: LR = 0.41505949:: MOM = 0.17440000\n",
      "19-Aug 17:03:31:INFO:root:ITER = 004500:: TRAIN obj-val = 0.00983830:: LR = 0.41340091:: MOM = 0.17600000\n",
      "19-Aug 17:03:33:INFO:root:\n",
      "19-Aug 17:03:33:INFO:root:## Performance on Validation Set after 4500 iterations\n",
      "19-Aug 17:03:33:INFO:root:---------------------------------------------------------\n",
      "19-Aug 17:03:33:INFO:root:  Accuracy (avg over 785) = 65.2229%\n",
      "19-Aug 17:03:33:INFO:root:---------------------------------------------------------\n",
      "19-Aug 17:03:33:INFO:root:\n",
      "19-Aug 17:03:33:INFO:root:Saving snapshot to snapshot-004500.jld...\n",
      "19-Aug 17:03:33:DEBUG:root:Saving parameters for layer fc1\n",
      "19-Aug 17:03:33:DEBUG:root:Saving parameters for layer fc2\n",
      "19-Aug 17:03:33:DEBUG:root:Saving parameters for layer out\n",
      "19-Aug 17:04:13:INFO:root:ITER = 004600:: TRAIN obj-val = 0.00037745:: LR = 0.41174896:: MOM = 0.17760000\n",
      "19-Aug 17:04:54:INFO:root:ITER = 004700:: TRAIN obj-val = 0.00042504:: LR = 0.40928340:: MOM = 0.18000000\n",
      "19-Aug 17:04:54:INFO:root:Loading existing model from mlp_1200_1200_0.1_0.5/snapshot-004500.jld\n",
      "19-Aug 17:04:54:DEBUG:root:Loading parameters for layer fc1\n",
      "19-Aug 17:04:54:DEBUG:root:Loading parameters for layer fc2\n",
      "19-Aug 17:04:54:DEBUG:root:Loading parameters for layer out\n",
      "19-Aug 17:04:54:DEBUG:root:Init network SVHN-validation\n",
      "[nunits=1200, base_mom=0.1, base_lr=0.5] => 0.6522292993630573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({:net=>************************************************************\n",
       "          NAME: SVHN-train\n",
       "       BACKEND: CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** AsyncHDF5DataLayer(train-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(20 x 20 x 1 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "............................................................\n",
       " *** InnerProductLayer(fc1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(20 x 20 x 1 x 100)\n",
       "    Outputs ---------------------------\n",
       "           fc1: Blob(1200 x 100)\n",
       "............................................................\n",
       " *** InnerProductLayer(fc2)\n",
       "    Inputs ----------------------------\n",
       "           fc1: Blob(1200 x 100)\n",
       "    Outputs ---------------------------\n",
       "           fc2: Blob(1200 x 100)\n",
       "............................................................\n",
       " *** InnerProductLayer(out)\n",
       "    Inputs ----------------------------\n",
       "           fc2: Blob(1200 x 100)\n",
       "    Outputs ---------------------------\n",
       "           out: Blob(62 x 100)\n",
       "............................................................\n",
       " *** SoftmaxLossLayer(loss)\n",
       "    Inputs ----------------------------\n",
       "           out: Blob(62 x 100)\n",
       "         label: Blob(1 x 100)\n",
       "************************************************************\n",
       ",:valid_net=>************************************************************\n",
       "          NAME: SVHN-validation\n",
       "       BACKEND: CPUBackend\n",
       "  ARCHITECTURE: 5 layers\n",
       "............................................................\n",
       " *** AsyncHDF5DataLayer(validation-data)\n",
       "    Outputs ---------------------------\n",
       "          data: Blob(20 x 20 x 1 x 785)\n",
       "         label: Blob(1 x 785)\n",
       "............................................................\n",
       " *** InnerProductLayer(fc1)\n",
       "    Inputs ----------------------------\n",
       "          data: Blob(20 x 20 x 1 x 785)\n",
       "    Outputs ---------------------------\n",
       "           fc1: Blob(1200 x 785)\n",
       "............................................................\n",
       " *** InnerProductLayer(fc2)\n",
       "    Inputs ----------------------------\n",
       "           fc1: Blob(1200 x 785)\n",
       "    Outputs ---------------------------\n",
       "           fc2: Blob(1200 x 785)\n",
       "............................................................\n",
       " *** InnerProductLayer(out)\n",
       "    Inputs ----------------------------\n",
       "           fc2: Blob(1200 x 785)\n",
       "    Outputs ---------------------------\n",
       "           out: Blob(62 x 785)\n",
       "............................................................\n",
       " *** AccuracyLayer(validation-accuracy)\n",
       "    Inputs ----------------------------\n",
       "           out: Blob(62 x 785)\n",
       "         label: Blob(1 x 785)\n",
       "************************************************************\n",
       ",:base_dir=>\"mlp_1200_1200_0.1_0.5\",:validLabels=>{0,1,5,7,14,19,21,15,24,24  …  21,46,21,59,14,55,22,21,14,40}},(1200,0.1,0.5),0.6522292993630573)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model, best_cfg, best_score = gridtune(estfun, evalfun, nunits, base_mom, base_lr; verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19-Aug 16:19:05:INFO:root:Constructing net SVHN-Test on CPUBackend...\n",
      "19-Aug 16:19:05:INFO:root:Topological sorting 5 layers...\n",
      "19-Aug 16:19:05:INFO:root:Setup layers...\n",
      "19-Aug 16:19:05:DEBUG:root:InnerProductLayer(fc1): sharing weights and bias\n",
      "19-Aug 16:19:05:DEBUG:root:InnerProductLayer(fc2): sharing weights and bias\n",
      "19-Aug 16:19:05:DEBUG:root:InnerProductLayer(out): sharing weights and bias\n",
      "19-Aug 16:19:05:INFO:root:Network constructed!\n",
      "************************************************************\n",
      "          NAME: SVHN-Test\n",
      "       BACKEND: CPUBackend\n",
      "  ARCHITECTURE: 5 layers\n",
      "............................................................\n",
      " *** AsyncHDF5DataLayer(hdf5-data)\n",
      "    Outputs ---------------------------\n",
      "          data: Blob(20 x 20 x 1 x 6220)\n",
      "         label: Blob(1 x 6220)\n",
      "............................................................\n",
      " *** InnerProductLayer(fc1)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(20 x 20 x 1 x 6220)\n",
      "    Outputs ---------------------------\n",
      "           fc1: Blob(2400 x 6220)\n",
      "............................................................\n",
      " *** InnerProductLayer(fc2)\n",
      "    Inputs ----------------------------\n",
      "           fc1: Blob(2400 x 6220)\n",
      "    Outputs ---------------------------\n",
      "           fc2: Blob(2400 x 6220)\n",
      "............................................................\n",
      " *** InnerProductLayer(out)\n",
      "    Inputs ----------------------------\n",
      "           fc2: Blob(2400 x 6220)\n",
      "    Outputs ---------------------------\n",
      "           out: Blob(62 x 6220)\n",
      "............................................................\n",
      " *** SoftmaxLayer(prob)\n",
      "    Inputs ----------------------------\n",
      "           out: Blob(62 x 6220)\n",
      "    Outputs ---------------------------\n",
      "          prob: Blob(62 x 6220)\n",
      "************************************************************\n",
      "\n",
      "19-Aug 16:19:05:INFO:root:Loading existing model from mlp_2400_2400_0.1_0.5/snapshot-004500.jld\n",
      "19-Aug 16:19:05:DEBUG:root:Loading parameters for layer fc1\n",
      "19-Aug 16:19:05:DEBUG:root:Loading parameters for layer fc2\n",
      "19-Aug 16:19:05:DEBUG:root:Loading parameters for layer out\n",
      "19-Aug 16:19:05:DEBUG:root:Init network SVHN-Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6220-element Array{Float64,1}:\n",
       " 17.0\n",
       " 19.0\n",
       "  3.0\n",
       "  2.0\n",
       " 30.0\n",
       "  6.0\n",
       " 25.0\n",
       " 24.0\n",
       " 56.0\n",
       " 20.0\n",
       " 14.0\n",
       "  5.0\n",
       " 20.0\n",
       "  ⋮  \n",
       "  4.0\n",
       " 10.0\n",
       " 19.0\n",
       " 11.0\n",
       " 19.0\n",
       "  3.0\n",
       "  8.0\n",
       " 15.0\n",
       " 28.0\n",
       " 36.0\n",
       " 14.0\n",
       " 36.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend = best_model[:net].backend\n",
    "\n",
    "common_layers = best_model[:net].layers[2:end-1]\n",
    "test_batch = size(testImages)[4]\n",
    "test_data_layer = AsyncHDF5DataLayer(source=\"data/test.txt\", batch_size=test_batch, shuffle=false)\n",
    "softmax_layer = SoftmaxLayer(name=\"prob\", tops=[:prob], bottoms=[:out])\n",
    "test_net = Net(\"SVHN-Test\", backend, [test_data_layer, common_layers..., softmax_layer])\n",
    "println(test_net)\n",
    "pred = predict(test_net, best_model[:base_dir])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = joinpath(path, \"juliaNN-Dropout-Submission.csv\")\n",
    "dic_rev = Dict(zip(values(dic), keys(dic)))\n",
    "labelsInfoTest[:Class] = map(k -> dic_rev[k], pred)\n",
    "writetable(filename, labelsInfoTest[:,[:ID, :Class]], separator=',', header=true)\n",
    "run(`sed -i '' 's/\"//g' $(filename)`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.10",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
