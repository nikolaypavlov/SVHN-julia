{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network main params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring Mocha...\n",
      " * CUDA       enabled [DEV=0] (MOCHA_USE_CUDA environment variable detected)\n",
      " * Native Ext disabled by default\n",
      "Mocha configured, continue loading module...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"hdf5-data\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_gpu = true\n",
    "ENV[\"MOCHA_USE_CUDA\"] = \"true\"\n",
    "ENV[\"OMP_NUM_THREADS\"] = 1\n",
    "blas_set_num_threads(1)\n",
    "\n",
    "using HDF5\n",
    "using Mocha\n",
    "srand(333)\n",
    "\n",
    "EPOCH = 47\n",
    "MAXITER = 90*EPOCH\n",
    "base_dir = \"snapshots\"\n",
    "path = \"hdf5-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Neural Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-Aug 07:02:09:INFO:root:Initializing CuDNN backend...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: CuDNN backend initialized!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-Aug 07:02:10:INFO:root:Constructing net SVHN-train on GPUBackend...\n",
      "31-Aug 07:02:10:INFO:root:Topological sorting 14 layers...\n",
      "31-Aug 07:02:10:INFO:root:Setup layers...\n",
      "31-Aug 07:02:13:INFO:root:Network constructed!\n",
      "31-Aug 07:02:13:INFO:root:Constructing net SVHN-train-prediction on GPUBackend...\n",
      "31-Aug 07:02:13:INFO:root:Topological sorting 9 layers...\n",
      "31-Aug 07:02:13:INFO:root:Setup layers...\n",
      "31-Aug 07:02:13:DEBUG:root:ConvolutionLayer(conv1): sharing filters and bias\n",
      "31-Aug 07:02:13:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip1): sharing weights and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip3): sharing weights and bias\n",
      "31-Aug 07:02:13:INFO:root:Network constructed!\n",
      "31-Aug 07:02:13:INFO:root:Constructing net SVHN-validation-prediction on GPUBackend...\n",
      "31-Aug 07:02:13:INFO:root:Topological sorting 9 layers...\n",
      "31-Aug 07:02:13:INFO:root:Setup layers...\n",
      "31-Aug 07:02:13:DEBUG:root:ConvolutionLayer(conv1): sharing filters and bias\n",
      "31-Aug 07:02:13:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip1): sharing weights and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias\n",
      "31-Aug 07:02:13:DEBUG:root:InnerProductLayer(ip3): sharing weights and bias\n",
      "31-Aug 07:02:13:INFO:root:Network constructed!\n",
      "************************************************************\n",
      "          NAME: SVHN-train\n",
      "       BACKEND: GPUBackend\n",
      "  ARCHITECTURE: 14 layers\n",
      "............................................................\n",
      " *** AsyncHDF5DataLayer(train-data)\n",
      "    Outputs ---------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "         label: Blob(1 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_in)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "............................................................\n",
      " *** ConvolutionLayer(conv1)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "    Outputs ---------------------------\n",
      "          conv: Blob(16 x 16 x 96 x 100)\n",
      "............................................................\n",
      " *** PoolingLayer(pool1)\n",
      "    Inputs ----------------------------\n",
      "          conv: Blob(16 x 16 x 96 x 100)\n",
      "    Outputs ---------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_conv1)\n",
      "    Inputs ----------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "............................................................\n",
      " *** ConvolutionLayer(conv2)\n",
      "    Inputs ----------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "    Outputs ---------------------------\n",
      "         conv2: Blob(4 x 4 x 128 x 100)\n",
      "............................................................\n",
      " *** PoolingLayer(pool2)\n",
      "    Inputs ----------------------------\n",
      "         conv2: Blob(4 x 4 x 128 x 100)\n",
      "    Outputs ---------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_conv2)\n",
      "    Inputs ----------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip1)\n",
      "    Inputs ----------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "    Outputs ---------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_ip1)\n",
      "    Inputs ----------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip2)\n",
      "    Inputs ----------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "    Outputs ---------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_ip2)\n",
      "    Inputs ----------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip3)\n",
      "    Inputs ----------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "    Outputs ---------------------------\n",
      "           out: Blob(62 x 100)\n",
      "............................................................\n",
      " *** SoftmaxLossLayer(loss)\n",
      "    Inputs ----------------------------\n",
      "           out: Blob(62 x 100)\n",
      "         label: Blob(1 x 100)\n",
      "************************************************************\n",
      "\n",
      "31-Aug 07:02:14:DEBUG:root:Checking network topology for back-propagation\n",
      "31-Aug 07:02:14:DEBUG:root:Init network SVHN-train\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter filter for layer conv1\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter bias for layer conv1\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter filter for layer conv2\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter bias for layer conv2\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter weight for layer ip1\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter bias for layer ip1\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter weight for layer ip2\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter bias for layer ip2\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter weight for layer ip3\n",
      "31-Aug 07:02:14:DEBUG:root:Init parameter bias for layer ip3\n",
      "31-Aug 07:02:15:DEBUG:root:Initializing coffee breaks\n",
      "31-Aug 07:02:15:DEBUG:root:Init network SVHN-train-prediction\n",
      "31-Aug 07:02:15:DEBUG:root:Init network SVHN-validation-prediction\n",
      "31-Aug 07:02:15:INFO:root:ITER = 000000:: TRAIN obj-val = 5.39170694:: LR = 0.01000000:: MOM = 0.95000000\n",
      "31-Aug 07:02:15:INFO:root:\n",
      "31-Aug 07:02:15:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "31-Aug 07:02:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:15:INFO:root:  Accuracy (avg over 4713) = 1.9096%\n",
      "31-Aug 07:02:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:15:INFO:root:\n",
      "31-Aug 07:02:15:INFO:root:\n",
      "31-Aug 07:02:15:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "31-Aug 07:02:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:15:INFO:root:  Accuracy (avg over 785) = 1.6561%\n",
      "31-Aug 07:02:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:15:INFO:root:\n",
      "31-Aug 07:02:15:DEBUG:root:Entering solver loop\n",
      "31-Aug 07:02:16:INFO:root:ITER = 000100:: TRAIN obj-val = 3.83920479:: LR = 0.00992565:: MOM = 0.95000000\n",
      "31-Aug 07:02:17:INFO:root:ITER = 000200:: TRAIN obj-val = 3.82622433:: LR = 0.00985258:: MOM = 0.95000000\n",
      "31-Aug 07:02:18:INFO:root:ITER = 000300:: TRAIN obj-val = 3.73376703:: LR = 0.00978075:: MOM = 0.95000000\n",
      "31-Aug 07:02:18:INFO:root:ITER = 000400:: TRAIN obj-val = 3.65147686:: LR = 0.00971013:: MOM = 0.95000000\n",
      "31-Aug 07:02:19:INFO:root:ITER = 000500:: TRAIN obj-val = 3.77952218:: LR = 0.00964069:: MOM = 0.95000000\n",
      "31-Aug 07:02:19:INFO:root:\n",
      "31-Aug 07:02:19:INFO:root:## Performance on Validation Set after 500 iterations\n",
      "31-Aug 07:02:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:19:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:19:INFO:root:\n",
      "31-Aug 07:02:19:INFO:root:\n",
      "31-Aug 07:02:19:INFO:root:## Performance on Validation Set after 500 iterations\n",
      "31-Aug 07:02:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:19:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:19:INFO:root:\n",
      "31-Aug 07:02:20:INFO:root:ITER = 000600:: TRAIN obj-val = 3.80877972:: LR = 0.00957239:: MOM = 0.95000000\n",
      "31-Aug 07:02:21:INFO:root:ITER = 000700:: TRAIN obj-val = 3.76527071:: LR = 0.00950522:: MOM = 0.95000000\n",
      "31-Aug 07:02:21:INFO:root:ITER = 000800:: TRAIN obj-val = 3.74441600:: LR = 0.00943913:: MOM = 0.95000000\n",
      "31-Aug 07:02:22:INFO:root:ITER = 000900:: TRAIN obj-val = 3.68015146:: LR = 0.00937411:: MOM = 0.95000000\n",
      "31-Aug 07:02:23:INFO:root:ITER = 001000:: TRAIN obj-val = 3.84880304:: LR = 0.00931012:: MOM = 0.95000000\n",
      "31-Aug 07:02:23:INFO:root:\n",
      "31-Aug 07:02:23:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "31-Aug 07:02:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:23:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:23:INFO:root:\n",
      "31-Aug 07:02:23:INFO:root:\n",
      "31-Aug 07:02:23:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "31-Aug 07:02:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:23:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:23:INFO:root:\n",
      "31-Aug 07:02:24:INFO:root:ITER = 001100:: TRAIN obj-val = 3.66495800:: LR = 0.00924715:: MOM = 0.95000000\n",
      "31-Aug 07:02:24:INFO:root:ITER = 001200:: TRAIN obj-val = 3.70248437:: LR = 0.00918515:: MOM = 0.95000000\n",
      "31-Aug 07:02:25:INFO:root:ITER = 001300:: TRAIN obj-val = 3.77199197:: LR = 0.00912412:: MOM = 0.95000000\n",
      "31-Aug 07:02:26:INFO:root:ITER = 001400:: TRAIN obj-val = 3.77789521:: LR = 0.00906403:: MOM = 0.95000000\n",
      "31-Aug 07:02:27:INFO:root:ITER = 001500:: TRAIN obj-val = 3.75765324:: LR = 0.00900485:: MOM = 0.95000000\n",
      "31-Aug 07:02:27:INFO:root:\n",
      "31-Aug 07:02:27:INFO:root:## Performance on Validation Set after 1500 iterations\n",
      "31-Aug 07:02:27:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:27:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:27:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:27:INFO:root:\n",
      "31-Aug 07:02:27:INFO:root:\n",
      "31-Aug 07:02:27:INFO:root:## Performance on Validation Set after 1500 iterations\n",
      "31-Aug 07:02:27:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:27:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:27:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:27:INFO:root:\n",
      "31-Aug 07:02:27:INFO:root:ITER = 001600:: TRAIN obj-val = 3.71714687:: LR = 0.00894657:: MOM = 0.95000000\n",
      "31-Aug 07:02:28:INFO:root:ITER = 001700:: TRAIN obj-val = 3.84401584:: LR = 0.00888916:: MOM = 0.95000000\n",
      "31-Aug 07:02:29:INFO:root:ITER = 001800:: TRAIN obj-val = 3.73714995:: LR = 0.00883260:: MOM = 0.95000000\n",
      "31-Aug 07:02:30:INFO:root:ITER = 001900:: TRAIN obj-val = 3.83986449:: LR = 0.00877687:: MOM = 0.95000000\n",
      "31-Aug 07:02:30:INFO:root:ITER = 002000:: TRAIN obj-val = 3.77704835:: LR = 0.00872196:: MOM = 0.95000000\n",
      "31-Aug 07:02:30:INFO:root:\n",
      "31-Aug 07:02:30:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "31-Aug 07:02:30:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:30:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:30:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:30:INFO:root:\n",
      "31-Aug 07:02:30:INFO:root:\n",
      "31-Aug 07:02:30:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "31-Aug 07:02:30:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:30:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:30:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:30:INFO:root:\n",
      "31-Aug 07:02:31:INFO:root:ITER = 002100:: TRAIN obj-val = 3.88544941:: LR = 0.00866784:: MOM = 0.95000000\n",
      "31-Aug 07:02:32:INFO:root:ITER = 002200:: TRAIN obj-val = 3.65455103:: LR = 0.00861450:: MOM = 0.95000000\n",
      "31-Aug 07:02:33:INFO:root:ITER = 002300:: TRAIN obj-val = 3.53691888:: LR = 0.00856192:: MOM = 0.95000000\n",
      "31-Aug 07:02:33:INFO:root:ITER = 002400:: TRAIN obj-val = 3.67689753:: LR = 0.00851008:: MOM = 0.95000000\n",
      "31-Aug 07:02:34:INFO:root:ITER = 002500:: TRAIN obj-val = 3.64859247:: LR = 0.00845897:: MOM = 0.95000000\n",
      "31-Aug 07:02:34:INFO:root:\n",
      "31-Aug 07:02:34:INFO:root:## Performance on Validation Set after 2500 iterations\n",
      "31-Aug 07:02:34:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:34:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:34:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:34:INFO:root:\n",
      "31-Aug 07:02:34:INFO:root:\n",
      "31-Aug 07:02:34:INFO:root:## Performance on Validation Set after 2500 iterations\n",
      "31-Aug 07:02:34:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:34:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:34:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:34:INFO:root:\n",
      "31-Aug 07:02:35:INFO:root:ITER = 002600:: TRAIN obj-val = 3.82387829:: LR = 0.00840857:: MOM = 0.95000000\n",
      "31-Aug 07:02:36:INFO:root:ITER = 002700:: TRAIN obj-val = 3.86401987:: LR = 0.00835886:: MOM = 0.95000000\n",
      "31-Aug 07:02:36:INFO:root:ITER = 002800:: TRAIN obj-val = 3.69781923:: LR = 0.00830984:: MOM = 0.95000000\n",
      "31-Aug 07:02:37:INFO:root:ITER = 002900:: TRAIN obj-val = 3.76113153:: LR = 0.00826148:: MOM = 0.95000000\n",
      "31-Aug 07:02:38:INFO:root:ITER = 003000:: TRAIN obj-val = 3.62155795:: LR = 0.00821377:: MOM = 0.95000000\n",
      "31-Aug 07:02:38:INFO:root:\n",
      "31-Aug 07:02:38:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "31-Aug 07:02:38:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:38:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:38:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:38:INFO:root:\n",
      "31-Aug 07:02:38:INFO:root:\n",
      "31-Aug 07:02:38:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "31-Aug 07:02:38:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:38:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:38:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:38:INFO:root:\n",
      "31-Aug 07:02:39:INFO:root:ITER = 003100:: TRAIN obj-val = 3.89419365:: LR = 0.00816670:: MOM = 0.95000000\n",
      "31-Aug 07:02:39:INFO:root:ITER = 003200:: TRAIN obj-val = 3.77954769:: LR = 0.00812025:: MOM = 0.95000000\n",
      "31-Aug 07:02:40:INFO:root:ITER = 003300:: TRAIN obj-val = 3.79495049:: LR = 0.00807442:: MOM = 0.95000000\n",
      "31-Aug 07:02:41:INFO:root:ITER = 003400:: TRAIN obj-val = 3.76385164:: LR = 0.00802918:: MOM = 0.95000000\n",
      "31-Aug 07:02:42:INFO:root:ITER = 003500:: TRAIN obj-val = 3.91854286:: LR = 0.00798454:: MOM = 0.95000000\n",
      "31-Aug 07:02:42:INFO:root:\n",
      "31-Aug 07:02:42:INFO:root:## Performance on Validation Set after 3500 iterations\n",
      "31-Aug 07:02:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:42:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:42:INFO:root:\n",
      "31-Aug 07:02:42:INFO:root:\n",
      "31-Aug 07:02:42:INFO:root:## Performance on Validation Set after 3500 iterations\n",
      "31-Aug 07:02:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:42:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:42:INFO:root:\n",
      "31-Aug 07:02:42:INFO:root:ITER = 003600:: TRAIN obj-val = 3.85710001:: LR = 0.00794046:: MOM = 0.95000000\n",
      "31-Aug 07:02:43:INFO:root:ITER = 003700:: TRAIN obj-val = 3.84902716:: LR = 0.00789695:: MOM = 0.95000000\n",
      "31-Aug 07:02:44:INFO:root:ITER = 003800:: TRAIN obj-val = 3.87014890:: LR = 0.00785400:: MOM = 0.95000000\n",
      "31-Aug 07:02:45:INFO:root:ITER = 003900:: TRAIN obj-val = 3.81727171:: LR = 0.00781158:: MOM = 0.95000000\n",
      "31-Aug 07:02:45:INFO:root:ITER = 004000:: TRAIN obj-val = 3.62471652:: LR = 0.00776970:: MOM = 0.95000000\n",
      "31-Aug 07:02:45:INFO:root:\n",
      "31-Aug 07:02:45:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "31-Aug 07:02:45:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:45:INFO:root:  Accuracy (avg over 4713) = 7.4899%\n",
      "31-Aug 07:02:45:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:45:INFO:root:\n",
      "31-Aug 07:02:45:INFO:root:\n",
      "31-Aug 07:02:45:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "31-Aug 07:02:45:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:45:INFO:root:  Accuracy (avg over 785) = 6.8790%\n",
      "31-Aug 07:02:45:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:45:INFO:root:\n",
      "31-Aug 07:02:46:INFO:root:ITER = 004100:: TRAIN obj-val = 3.71633387:: LR = 0.00772833:: MOM = 0.95000000\n",
      "31-Aug 07:02:47:INFO:root:ITER = 004200:: TRAIN obj-val = 3.60750675:: LR = 0.00768748:: MOM = 0.95000000\n",
      "31-Aug 07:02:47:DEBUG:root:Destroying network SVHN-train\n",
      "31-Aug 07:02:47:INFO:root:AsyncHDF5DataLayer: Stopping IO task...\n",
      "31-Aug 07:02:47:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...\n",
      "31-Aug 07:02:47:INFO:root:Shutting down CuDNN backend...\n",
      "31-Aug 07:02:48:INFO:root:CuDNN Backend shutdown finished!\n"
     ]
    }
   ],
   "source": [
    "data_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"$(path)/train.txt\", batch_size=100)\n",
    "conv_layer  = ConvolutionLayer(name=\"conv1\", n_filter=96, kernel=(5,5), bottoms=[:data], tops=[:conv])\n",
    "pool_layer  = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2), bottoms=[:conv], tops=[:pool])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=128, kernel=(5,5), bottoms=[:pool], tops=[:conv2])\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride=(2,2), bottoms=[:conv2], tops=[:pool2])\n",
    "fc1_layer   = InnerProductLayer(name=\"ip1\", output_dim=2400, neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\n",
    "fc2_layer   = InnerProductLayer(name=\"ip2\", output_dim=1200, neuron=Neurons.ReLU(), bottoms=[:ip1], tops=[:ip2])\n",
    "fc3_layer   = InnerProductLayer(name=\"ip3\", output_dim=62, bottoms=[:ip2], tops=[:out])\n",
    "loss_layer  = SoftmaxLossLayer(name=\"loss\", bottoms=[:out,:label])\n",
    "\n",
    "backend = use_gpu ? GPUBackend() : CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "# setup dropout for the different layers\n",
    "# we use 20% dropout on the inputs and 50% dropout in the hidden layers\n",
    "# as these values were previously found to be good defaults\n",
    "drop_input = DropoutLayer(name=\"drop_in\", bottoms=[:data], ratio=0.1)\n",
    "drop_conv1 = DropoutLayer(name=\"drop_conv1\", bottoms=[:pool], ratio=0.2)\n",
    "drop_conv2 = DropoutLayer(name=\"drop_conv2\", bottoms=[:pool2], ratio=0.2)\n",
    "drop_ip1 = DropoutLayer(name=\"drop_ip1\", bottoms=[:ip1], ratio=0.5)\n",
    "drop_ip2= DropoutLayer(name=\"drop_ip2\", bottoms=[:ip2], ratio=0.5)\n",
    "\n",
    "common_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer, fc1_layer, fc2_layer, fc3_layer]\n",
    "drop_layers = [drop_input, drop_conv1, drop_conv2, drop_ip1, drop_ip2]\n",
    "# put training net together, note that the correct ordering will automatically be established by the constructor\n",
    "net = Net(\"SVHN-train\", backend, [data_layer, common_layers..., drop_layers..., loss_layer])\n",
    "\n",
    "# Configure accuracy check on train set during training process\n",
    "full_data_layer = AsyncHDF5DataLayer( name=\"train-full-data\", source=\"$(path)/train.txt\", batch_size=4713)\n",
    "full_acc_layer = AccuracyLayer(name=\"full_train\", bottoms=[:out, :label], report_error=true)\n",
    "train_net = Net(\"SVHN-train-prediction\", backend, [full_data_layer, common_layers..., full_acc_layer])\n",
    "\n",
    "# Configure accuracy check on validation set during training process\n",
    "valid_data_layer = AsyncHDF5DataLayer(name=\"validation-data\", source=\"$(path)/validation.txt\", batch_size=785)\n",
    "valid_acc_layer = AccuracyLayer(name=\"validation\", bottoms=[:out, :label], report_error=true)\n",
    "valid_net = Net(\"SVHN-validation-prediction\", backend, [valid_data_layer, common_layers..., valid_acc_layer])\n",
    "\n",
    "println(net)\n",
    "\n",
    "params = SolverParameters(max_iter=MAXITER, \n",
    "                          regu_coef=0.0,\n",
    "                          mom_policy=MomPolicy.Fixed(0.95),\n",
    "                          lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75), \n",
    "                          load_from=base_dir)\n",
    "\n",
    "solver = SGD(params)\n",
    "\n",
    "#setup_coffee_lounge(solver, save_into=\"$(base_dir)/statistics.jld\", every_n_iter=5000)\n",
    "\n",
    "# report training progress every 100 iterations\n",
    "add_coffee_break(solver, TrainingSummary(show_lr=true, show_mom=true), every_n_iter=100)\n",
    "\n",
    "# Report train perfomance every 500 iterations\n",
    "add_coffee_break(solver, ValidationPerformance(train_net), every_n_iter=500)\n",
    "\n",
    "# Report validation perfomance every 500 iterations\n",
    "add_coffee_break(solver, ValidationPerformance(valid_net), every_n_iter=500)\n",
    "\n",
    "solve(solver, net)\n",
    "\n",
    "destroy(net)\n",
    "shutdown(backend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain on CPU backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_gpu = false\n",
    "ENV[\"MOCHA_USE_CUDA\"] = \"false\"\n",
    "ENV[\"MOCHA_USE_NATIVE_EXT\"] = \"true\"\n",
    "\n",
    "using HDF5\n",
    "using Mocha\n",
    "srand(333)\n",
    "\n",
    "EPOCH = 47\n",
    "MAXITER = 90*EPOCH\n",
    "base_dir = \"snapshots\"\n",
    "path = \"hdf5-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Neural Network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31-Aug 07:02:51:INFO:root:Constructing net SVHN-train on CPUBackend...\n",
      "31-Aug 07:02:51:INFO:root:Topological sorting 14 layers...\n",
      "31-Aug 07:02:51:INFO:root:Setup layers...\n",
      "31-Aug 07:02:52:INFO:root:Network constructed!\n",
      "31-Aug 07:02:52:INFO:root:Constructing net SVHN-train-prediction on CPUBackend...\n",
      "31-Aug 07:02:52:INFO:root:Topological sorting 9 layers...\n",
      "31-Aug 07:02:52:INFO:root:Setup layers...\n",
      "31-Aug 07:02:52:DEBUG:root:ConvolutionLayer(conv1): sharing filters and bias\n",
      "31-Aug 07:02:52:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip1): sharing weights and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip3): sharing weights and bias\n",
      "31-Aug 07:02:52:INFO:root:Network constructed!\n",
      "31-Aug 07:02:52:INFO:root:Constructing net SVHN-validation-prediction on CPUBackend...\n",
      "31-Aug 07:02:52:INFO:root:Topological sorting 9 layers...\n",
      "31-Aug 07:02:52:INFO:root:Setup layers...\n",
      "31-Aug 07:02:52:DEBUG:root:ConvolutionLayer(conv1): sharing filters and bias\n",
      "31-Aug 07:02:52:DEBUG:root:ConvolutionLayer(conv2): sharing filters and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip1): sharing weights and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip2): sharing weights and bias\n",
      "31-Aug 07:02:52:DEBUG:root:InnerProductLayer(ip3): sharing weights and bias\n",
      "31-Aug 07:02:52:INFO:root:Network constructed!\n",
      "************************************************************\n",
      "          NAME: SVHN-train\n",
      "       BACKEND: CPUBackend\n",
      "  ARCHITECTURE: 14 layers\n",
      "............................................................\n",
      " *** AsyncHDF5DataLayer(train-data)\n",
      "    Outputs ---------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "         label: Blob(1 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_in)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "............................................................\n",
      " *** ConvolutionLayer(conv1)\n",
      "    Inputs ----------------------------\n",
      "          data: Blob(20 x 20 x 1 x 100)\n",
      "    Outputs ---------------------------\n",
      "          conv: Blob(16 x 16 x 96 x 100)\n",
      "............................................................\n",
      " *** PoolingLayer(pool1)\n",
      "    Inputs ----------------------------\n",
      "          conv: Blob(16 x 16 x 96 x 100)\n",
      "    Outputs ---------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_conv1)\n",
      "    Inputs ----------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "............................................................\n",
      " *** ConvolutionLayer(conv2)\n",
      "    Inputs ----------------------------\n",
      "          pool: Blob(8 x 8 x 96 x 100)\n",
      "    Outputs ---------------------------\n",
      "         conv2: Blob(4 x 4 x 128 x 100)\n",
      "............................................................\n",
      " *** PoolingLayer(pool2)\n",
      "    Inputs ----------------------------\n",
      "         conv2: Blob(4 x 4 x 128 x 100)\n",
      "    Outputs ---------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_conv2)\n",
      "    Inputs ----------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip1)\n",
      "    Inputs ----------------------------\n",
      "         pool2: Blob(2 x 2 x 128 x 100)\n",
      "    Outputs ---------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_ip1)\n",
      "    Inputs ----------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip2)\n",
      "    Inputs ----------------------------\n",
      "           ip1: Blob(2400 x 100)\n",
      "    Outputs ---------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "............................................................\n",
      " *** DropoutLayer(drop_ip2)\n",
      "    Inputs ----------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "............................................................\n",
      " *** InnerProductLayer(ip3)\n",
      "    Inputs ----------------------------\n",
      "           ip2: Blob(1200 x 100)\n",
      "    Outputs ---------------------------\n",
      "           out: Blob(62 x 100)\n",
      "............................................................\n",
      " *** SoftmaxLossLayer(loss)\n",
      "    Inputs ----------------------------\n",
      "           out: Blob(62 x 100)\n",
      "         label: Blob(1 x 100)\n",
      "************************************************************\n",
      "\n",
      "31-Aug 07:02:53:DEBUG:root:Checking network topology for back-propagation\n",
      "31-Aug 07:02:53:DEBUG:root:Init network SVHN-train\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter filter for layer conv1\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter bias for layer conv1\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter filter for layer conv2\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter bias for layer conv2\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter weight for layer ip1\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter bias for layer ip1\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter weight for layer ip2\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter bias for layer ip2\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter weight for layer ip3\n",
      "31-Aug 07:02:53:DEBUG:root:Init parameter bias for layer ip3\n",
      "31-Aug 07:02:54:DEBUG:root:Initializing coffee breaks\n",
      "31-Aug 07:02:54:DEBUG:root:Init network SVHN-train-prediction\n",
      "31-Aug 07:02:54:DEBUG:root:Init network SVHN-validation-prediction\n",
      "31-Aug 07:02:54:INFO:root:ITER = 000000:: TRAIN obj-val = 5.52814341:: LR = 0.01000000:: MOM = 0.95000000\n",
      "31-Aug 07:02:58:INFO:root:\n",
      "31-Aug 07:02:58:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "31-Aug 07:02:58:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:58:INFO:root:  Accuracy (avg over 4713) = 0.8699%\n",
      "31-Aug 07:02:58:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:58:INFO:root:\n",
      "31-Aug 07:02:59:INFO:root:\n",
      "31-Aug 07:02:59:INFO:root:## Performance on Validation Set after 0 iterations\n",
      "31-Aug 07:02:59:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:59:INFO:root:  Accuracy (avg over 785) = 1.0191%\n",
      "31-Aug 07:02:59:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:02:59:INFO:root:\n",
      "31-Aug 07:02:59:DEBUG:root:Entering solver loop\n",
      "31-Aug 07:03:28:INFO:root:ITER = 000100:: TRAIN obj-val = 2.81499076:: LR = 0.00992565:: MOM = 0.95000000\n",
      "31-Aug 07:03:57:INFO:root:ITER = 000200:: TRAIN obj-val = 2.27502489:: LR = 0.00985258:: MOM = 0.95000000\n",
      "31-Aug 07:04:26:INFO:root:ITER = 000300:: TRAIN obj-val = 1.72542882:: LR = 0.00978075:: MOM = 0.95000000\n",
      "31-Aug 07:04:55:INFO:root:ITER = 000400:: TRAIN obj-val = 1.52528739:: LR = 0.00971013:: MOM = 0.95000000\n",
      "31-Aug 07:05:23:INFO:root:ITER = 000500:: TRAIN obj-val = 1.55601394:: LR = 0.00964069:: MOM = 0.95000000\n",
      "31-Aug 07:05:28:INFO:root:\n",
      "31-Aug 07:05:28:INFO:root:## Performance on Validation Set after 500 iterations\n",
      "31-Aug 07:05:28:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:05:28:INFO:root:  Accuracy (avg over 4713) = 74.8992%\n",
      "31-Aug 07:05:28:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:05:28:INFO:root:\n",
      "31-Aug 07:05:28:INFO:root:\n",
      "31-Aug 07:05:28:INFO:root:## Performance on Validation Set after 500 iterations\n",
      "31-Aug 07:05:28:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:05:28:INFO:root:  Accuracy (avg over 785) = 60.3822%\n",
      "31-Aug 07:05:28:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:05:28:INFO:root:\n",
      "31-Aug 07:05:57:INFO:root:ITER = 000600:: TRAIN obj-val = 1.30082130:: LR = 0.00957239:: MOM = 0.95000000\n",
      "31-Aug 07:06:25:INFO:root:ITER = 000700:: TRAIN obj-val = 1.25079620:: LR = 0.00950522:: MOM = 0.95000000\n",
      "31-Aug 07:06:54:INFO:root:ITER = 000800:: TRAIN obj-val = 0.99412310:: LR = 0.00943913:: MOM = 0.95000000\n",
      "31-Aug 07:07:22:INFO:root:ITER = 000900:: TRAIN obj-val = 0.97867435:: LR = 0.00937411:: MOM = 0.95000000\n",
      "31-Aug 07:07:51:INFO:root:ITER = 001000:: TRAIN obj-val = 0.80841047:: LR = 0.00931012:: MOM = 0.95000000\n",
      "31-Aug 07:07:55:INFO:root:\n",
      "31-Aug 07:07:55:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "31-Aug 07:07:55:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:07:55:INFO:root:  Accuracy (avg over 4713) = 89.1364%\n",
      "31-Aug 07:07:55:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:07:55:INFO:root:\n",
      "31-Aug 07:07:56:INFO:root:\n",
      "31-Aug 07:07:56:INFO:root:## Performance on Validation Set after 1000 iterations\n",
      "31-Aug 07:07:56:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:07:56:INFO:root:  Accuracy (avg over 785) = 66.4968%\n",
      "31-Aug 07:07:56:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:07:56:INFO:root:\n",
      "31-Aug 07:08:25:INFO:root:ITER = 001100:: TRAIN obj-val = 0.96761602:: LR = 0.00924715:: MOM = 0.95000000\n",
      "31-Aug 07:08:53:INFO:root:ITER = 001200:: TRAIN obj-val = 0.68203390:: LR = 0.00918515:: MOM = 0.95000000\n",
      "31-Aug 07:09:22:INFO:root:ITER = 001300:: TRAIN obj-val = 0.79928261:: LR = 0.00912412:: MOM = 0.95000000\n",
      "31-Aug 07:09:50:INFO:root:ITER = 001400:: TRAIN obj-val = 1.03146625:: LR = 0.00906403:: MOM = 0.95000000\n",
      "31-Aug 07:10:19:INFO:root:ITER = 001500:: TRAIN obj-val = 0.74192995:: LR = 0.00900485:: MOM = 0.95000000\n",
      "31-Aug 07:10:23:INFO:root:\n",
      "31-Aug 07:10:23:INFO:root:## Performance on Validation Set after 1500 iterations\n",
      "31-Aug 07:10:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:10:23:INFO:root:  Accuracy (avg over 4713) = 94.7804%\n",
      "31-Aug 07:10:23:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:10:23:INFO:root:\n",
      "31-Aug 07:10:24:INFO:root:\n",
      "31-Aug 07:10:24:INFO:root:## Performance on Validation Set after 1500 iterations\n",
      "31-Aug 07:10:24:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:10:24:INFO:root:  Accuracy (avg over 785) = 69.1720%\n",
      "31-Aug 07:10:24:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:10:24:INFO:root:\n",
      "31-Aug 07:10:52:INFO:root:ITER = 001600:: TRAIN obj-val = 0.54540503:: LR = 0.00894657:: MOM = 0.95000000\n",
      "31-Aug 07:11:21:INFO:root:ITER = 001700:: TRAIN obj-val = 0.72947276:: LR = 0.00888916:: MOM = 0.95000000\n",
      "31-Aug 07:11:49:INFO:root:ITER = 001800:: TRAIN obj-val = 0.86992365:: LR = 0.00883260:: MOM = 0.95000000\n",
      "31-Aug 07:12:18:INFO:root:ITER = 001900:: TRAIN obj-val = 0.93897963:: LR = 0.00877687:: MOM = 0.95000000\n",
      "31-Aug 07:12:46:INFO:root:ITER = 002000:: TRAIN obj-val = 0.57877070:: LR = 0.00872196:: MOM = 0.95000000\n",
      "31-Aug 07:12:51:INFO:root:\n",
      "31-Aug 07:12:51:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "31-Aug 07:12:51:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:12:51:INFO:root:  Accuracy (avg over 4713) = 96.3081%\n",
      "31-Aug 07:12:51:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:12:51:INFO:root:\n",
      "31-Aug 07:12:52:INFO:root:\n",
      "31-Aug 07:12:52:INFO:root:## Performance on Validation Set after 2000 iterations\n",
      "31-Aug 07:12:52:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:12:52:INFO:root:  Accuracy (avg over 785) = 69.0446%\n",
      "31-Aug 07:12:52:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:12:52:INFO:root:\n",
      "31-Aug 07:13:20:INFO:root:ITER = 002100:: TRAIN obj-val = 0.37635750:: LR = 0.00866784:: MOM = 0.95000000\n",
      "31-Aug 07:13:49:INFO:root:ITER = 002200:: TRAIN obj-val = 0.51952934:: LR = 0.00861450:: MOM = 0.95000000\n",
      "31-Aug 07:14:17:INFO:root:ITER = 002300:: TRAIN obj-val = 0.52180338:: LR = 0.00856192:: MOM = 0.95000000\n",
      "31-Aug 07:14:45:INFO:root:ITER = 002400:: TRAIN obj-val = 0.58350009:: LR = 0.00851008:: MOM = 0.95000000\n",
      "31-Aug 07:15:14:INFO:root:ITER = 002500:: TRAIN obj-val = 0.61754829:: LR = 0.00845897:: MOM = 0.95000000\n",
      "31-Aug 07:15:18:INFO:root:\n",
      "31-Aug 07:15:18:INFO:root:## Performance on Validation Set after 2500 iterations\n",
      "31-Aug 07:15:18:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:15:18:INFO:root:  Accuracy (avg over 4713) = 97.8994%\n",
      "31-Aug 07:15:18:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:15:18:INFO:root:\n",
      "31-Aug 07:15:19:INFO:root:\n",
      "31-Aug 07:15:19:INFO:root:## Performance on Validation Set after 2500 iterations\n",
      "31-Aug 07:15:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:15:19:INFO:root:  Accuracy (avg over 785) = 67.8981%\n",
      "31-Aug 07:15:19:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:15:19:INFO:root:\n",
      "31-Aug 07:15:48:INFO:root:ITER = 002600:: TRAIN obj-val = 0.43750209:: LR = 0.00840857:: MOM = 0.95000000\n",
      "31-Aug 07:16:16:INFO:root:ITER = 002700:: TRAIN obj-val = 0.32254893:: LR = 0.00835886:: MOM = 0.95000000\n",
      "31-Aug 07:16:45:INFO:root:ITER = 002800:: TRAIN obj-val = 0.53212577:: LR = 0.00830984:: MOM = 0.95000000\n",
      "31-Aug 07:17:13:INFO:root:ITER = 002900:: TRAIN obj-val = 0.58384246:: LR = 0.00826148:: MOM = 0.95000000\n",
      "31-Aug 07:17:41:INFO:root:ITER = 003000:: TRAIN obj-val = 0.65980387:: LR = 0.00821377:: MOM = 0.95000000\n",
      "31-Aug 07:17:46:INFO:root:\n",
      "31-Aug 07:17:46:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "31-Aug 07:17:46:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:17:46:INFO:root:  Accuracy (avg over 4713) = 98.1540%\n",
      "31-Aug 07:17:46:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:17:46:INFO:root:\n",
      "31-Aug 07:17:47:INFO:root:\n",
      "31-Aug 07:17:47:INFO:root:## Performance on Validation Set after 3000 iterations\n",
      "31-Aug 07:17:47:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:17:47:INFO:root:  Accuracy (avg over 785) = 68.0255%\n",
      "31-Aug 07:17:47:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:17:47:INFO:root:\n",
      "31-Aug 07:18:15:INFO:root:ITER = 003100:: TRAIN obj-val = 0.46400508:: LR = 0.00816670:: MOM = 0.95000000\n",
      "31-Aug 07:18:44:INFO:root:ITER = 003200:: TRAIN obj-val = 0.46727431:: LR = 0.00812025:: MOM = 0.95000000\n",
      "31-Aug 07:19:12:INFO:root:ITER = 003300:: TRAIN obj-val = 0.43900207:: LR = 0.00807442:: MOM = 0.95000000\n",
      "31-Aug 07:19:41:INFO:root:ITER = 003400:: TRAIN obj-val = 0.57616735:: LR = 0.00802918:: MOM = 0.95000000\n",
      "31-Aug 07:20:09:INFO:root:ITER = 003500:: TRAIN obj-val = 0.37438929:: LR = 0.00798454:: MOM = 0.95000000\n",
      "31-Aug 07:20:14:INFO:root:\n",
      "31-Aug 07:20:14:INFO:root:## Performance on Validation Set after 3500 iterations\n",
      "31-Aug 07:20:14:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:20:14:INFO:root:  Accuracy (avg over 4713) = 99.0664%\n",
      "31-Aug 07:20:14:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:20:14:INFO:root:\n",
      "31-Aug 07:20:15:INFO:root:\n",
      "31-Aug 07:20:15:INFO:root:## Performance on Validation Set after 3500 iterations\n",
      "31-Aug 07:20:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:20:15:INFO:root:  Accuracy (avg over 785) = 69.6815%\n",
      "31-Aug 07:20:15:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:20:15:INFO:root:\n",
      "31-Aug 07:20:43:INFO:root:ITER = 003600:: TRAIN obj-val = 0.38137400:: LR = 0.00794046:: MOM = 0.95000000\n",
      "31-Aug 07:21:11:INFO:root:ITER = 003700:: TRAIN obj-val = 0.45093399:: LR = 0.00789695:: MOM = 0.95000000\n",
      "31-Aug 07:21:40:INFO:root:ITER = 003800:: TRAIN obj-val = 0.25379905:: LR = 0.00785400:: MOM = 0.95000000\n",
      "31-Aug 07:22:08:INFO:root:ITER = 003900:: TRAIN obj-val = 0.36650798:: LR = 0.00781158:: MOM = 0.95000000\n",
      "31-Aug 07:22:37:INFO:root:ITER = 004000:: TRAIN obj-val = 0.17318891:: LR = 0.00776970:: MOM = 0.95000000\n",
      "31-Aug 07:22:42:INFO:root:\n",
      "31-Aug 07:22:42:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "31-Aug 07:22:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:22:42:INFO:root:  Accuracy (avg over 4713) = 99.1725%\n",
      "31-Aug 07:22:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:22:42:INFO:root:\n",
      "31-Aug 07:22:42:INFO:root:\n",
      "31-Aug 07:22:42:INFO:root:## Performance on Validation Set after 4000 iterations\n",
      "31-Aug 07:22:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:22:42:INFO:root:  Accuracy (avg over 785) = 69.5541%\n",
      "31-Aug 07:22:42:INFO:root:---------------------------------------------------------\n",
      "31-Aug 07:22:42:INFO:root:\n",
      "31-Aug 07:23:11:INFO:root:ITER = 004100:: TRAIN obj-val = 0.35731655:: LR = 0.00772833:: MOM = 0.95000000\n",
      "31-Aug 07:23:39:INFO:root:ITER = 004200:: TRAIN obj-val = 0.30077767:: LR = 0.00768748:: MOM = 0.95000000\n",
      "31-Aug 07:23:48:DEBUG:root:Destroying network SVHN-train\n",
      "31-Aug 07:23:48:INFO:root:AsyncHDF5DataLayer: Stopping IO task...\n",
      "31-Aug 07:23:48:INFO:root:AsyncHDF5DataLayer: IO Task reaching the end...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{String,Array{AbstractParameter,1}} with 0 entries"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_layer  = AsyncHDF5DataLayer(name=\"train-data\", source=\"$(path)/train.txt\", batch_size=100)\n",
    "conv_layer  = ConvolutionLayer(name=\"conv1\", n_filter=96, kernel=(5,5), bottoms=[:data], tops=[:conv])\n",
    "pool_layer  = PoolingLayer(name=\"pool1\", kernel=(2,2), stride=(2,2), bottoms=[:conv], tops=[:pool])\n",
    "conv2_layer = ConvolutionLayer(name=\"conv2\", n_filter=128, kernel=(5,5), bottoms=[:pool], tops=[:conv2])\n",
    "pool2_layer = PoolingLayer(name=\"pool2\", kernel=(2,2), stride=(2,2), bottoms=[:conv2], tops=[:pool2])\n",
    "fc1_layer   = InnerProductLayer(name=\"ip1\", output_dim=2400, neuron=Neurons.ReLU(), bottoms=[:pool2], tops=[:ip1])\n",
    "fc2_layer   = InnerProductLayer(name=\"ip2\", output_dim=1200, neuron=Neurons.ReLU(), bottoms=[:ip1], tops=[:ip2])\n",
    "fc3_layer   = InnerProductLayer(name=\"ip3\", output_dim=62, bottoms=[:ip2], tops=[:out])\n",
    "loss_layer  = SoftmaxLossLayer(name=\"loss\", bottoms=[:out,:label])\n",
    "\n",
    "backend = use_gpu ? GPUBackend() : CPUBackend()\n",
    "init(backend)\n",
    "\n",
    "# setup dropout for the different layers\n",
    "# we use 20% dropout on the inputs and 50% dropout in the hidden layers\n",
    "# as these values were previously found to be good defaults\n",
    "drop_input = DropoutLayer(name=\"drop_in\", bottoms=[:data], ratio=0.1)\n",
    "drop_conv1 = DropoutLayer(name=\"drop_conv1\", bottoms=[:pool], ratio=0.2)\n",
    "drop_conv2 = DropoutLayer(name=\"drop_conv2\", bottoms=[:pool2], ratio=0.2)\n",
    "drop_ip1 = DropoutLayer(name=\"drop_ip1\", bottoms=[:ip1], ratio=0.5)\n",
    "drop_ip2= DropoutLayer(name=\"drop_ip2\", bottoms=[:ip2], ratio=0.5)\n",
    "\n",
    "common_layers = [conv_layer, pool_layer, conv2_layer, pool2_layer, fc1_layer, fc2_layer, fc3_layer]\n",
    "drop_layers = [drop_input, drop_conv1, drop_conv2, drop_ip1, drop_ip2]\n",
    "# put training net together, note that the correct ordering will automatically be established by the constructor\n",
    "net = Net(\"SVHN-train\", backend, [data_layer, common_layers..., drop_layers..., loss_layer])\n",
    "\n",
    "# Configure accuracy check on train set during training process\n",
    "full_data_layer = AsyncHDF5DataLayer( name=\"train-full-data\", source=\"$(path)/train.txt\", batch_size=4713)\n",
    "full_acc_layer = AccuracyLayer(name=\"full_train\", bottoms=[:out, :label], report_error=true)\n",
    "train_net = Net(\"SVHN-train-prediction\", backend, [full_data_layer, common_layers..., full_acc_layer])\n",
    "\n",
    "# Configure accuracy check on validation set during training process\n",
    "valid_data_layer = AsyncHDF5DataLayer(name=\"validation-data\", source=\"$(path)/validation.txt\", batch_size=785)\n",
    "valid_acc_layer = AccuracyLayer(name=\"validation\", bottoms=[:out, :label], report_error=true)\n",
    "valid_net = Net(\"SVHN-validation-prediction\", backend, [valid_data_layer, common_layers..., valid_acc_layer])\n",
    "\n",
    "println(net)\n",
    "\n",
    "params = SolverParameters(max_iter=MAXITER, \n",
    "                          regu_coef=0.0,\n",
    "                          mom_policy=MomPolicy.Fixed(0.95),\n",
    "                          lr_policy=LRPolicy.Inv(0.01, 0.0001, 0.75), \n",
    "                          load_from=base_dir)\n",
    "\n",
    "solver = SGD(params)\n",
    "\n",
    "#setup_coffee_lounge(solver, save_into=\"$(base_dir)/statistics.jld\", every_n_iter=5000)\n",
    "\n",
    "# report training progress every 100 iterations\n",
    "add_coffee_break(solver, TrainingSummary(show_lr=true, show_mom=true), every_n_iter=100)\n",
    "\n",
    "# Report train perfomance every 500 iterations\n",
    "add_coffee_break(solver, ValidationPerformance(train_net), every_n_iter=500)\n",
    "\n",
    "# Report validation perfomance every 500 iterations\n",
    "add_coffee_break(solver, ValidationPerformance(valid_net), every_n_iter=500)\n",
    "\n",
    "solve(solver, net)\n",
    "\n",
    "destroy(net)\n",
    "shutdown(backend)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.3.11",
   "language": "julia",
   "name": "julia-0.3"
  },
  "language_info": {
   "name": "julia",
   "version": "0.3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
